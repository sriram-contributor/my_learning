{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65382eb6-b998-4953-a31a-5ed9d9068a2b",
   "metadata": {},
   "source": [
    "### NLP & LLM - Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199912fd-18a7-4d72-a5e8-489f25bed380",
   "metadata": {},
   "source": [
    "That's a great choice! NLP and LLMs are at the forefront of Artificial Intelligence right now.\n",
    "\n",
    "In simple terms:\n",
    "* **Natural Language Processing (NLP)** is a broad field of computer science and AI focused on enabling computers to understand, interpret, and manipulate human language. Think of it as teaching computers to read and understand like we do.\n",
    "* **Large Language Models (LLMs)** are a specific *type* of AI model within NLP. They are \"large\" because they are trained on massive amounts of text data and have billions of parameters (variables they learn). This allows them to generate human-like text, translate languages, answer questions, and much more. You're interacting with one right now!\n",
    "\n",
    "Essentially, LLMs are a powerful tool used to achieve many NLP tasks.\n",
    "\n",
    "Let's explore this further with a plan:\n",
    "**Learning Plan:**\n",
    "\n",
    "1.  **What is NLP?** (Goals, challenges, common tasks)\n",
    "2.  **What are LLMs?** (How they fit into NLP, what makes them \"large\", basic working)\n",
    "3.  **How LLMs Learn** (Pre-training and fine-tuning)\n",
    "4.  **Key LLM Terms** (Tokens, Embeddings, Context Window)\n",
    "5.  **What Can LLMs Do?** (Applications and limitations)\n",
    "6.  **Putting it all together** (Summary and quiz/next steps)\n",
    "\n",
    "By the end, you'll have a solid understanding of what NLP and LLMs are, how they work, and how they relate to each other.\n",
    "\n",
    "Sound good? Shall we start with the basics of NLP?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963b484a-acd4-4be7-886d-8b27c05dc24d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "48e5bafa-5c76-4385-a0cb-ac77e8b3bf11",
   "metadata": {},
   "source": [
    "Great! Let's dive into **Natural Language Processing (NLP)**.\n",
    "\n",
    "Imagine you're trying to teach a very literal-minded robot to understand conversations. That's kind of like the goal of NLP! The main aim is to **enable computers to process, understand, and even generate human language** ‚Äì both written text and spoken words ‚Äì in a way that's meaningful and useful.\n",
    "\n",
    "But why is this so tricky for computers? Human language is full of nuances that we often take for granted:\n",
    "\n",
    "1.  **Ambiguity:** The same word can mean different things. Think of the word \"bank\". Does it mean a river bank or a financial institution? We use context to figure it out, but computers struggle with this.\n",
    "2.  **Context:** Understanding requires knowing the surrounding information. \"He is running\" means something different if we're talking about a marathon versus a political campaign.\n",
    "3.  **Sarcasm & Irony:** How do you teach a computer that \"Oh, *great* job!\" might actually mean the opposite? Tone and context are key, which are hard to program.\n",
    "4.  **Synonyms & Paraphrasing:** We can say the same thing in many ways (\"buy\", \"purchase\", \"acquire\"). Computers need to recognize these equivalences.\n",
    "5.  **World Knowledge:** Understanding often requires background knowledge about how the world works, which computers don't inherently possess.\n",
    "\n",
    "It's like teaching that robot not just dictionary definitions, but how to understand idioms, jokes, emotions, and the unsaid things in a conversation. That's the challenge and fascination of NLP!\n",
    "\n",
    "Does this initial explanation make sense? Do you have any questions about the goals or challenges of NLP, or would you like to try a quick activity to think about these challenges?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a10064-1795-4e1b-ab6d-bce90b1b007a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7fc330b6-ef54-4803-b295-13b1a5f2f45d",
   "metadata": {},
   "source": [
    "i like quick activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114e4d2e-9b06-4fc0-9254-07dba6e28128",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1121adb0-a2f5-45b6-8544-a11a09875e04",
   "metadata": {},
   "source": [
    "Awesome! Let's try one that highlights the **ambiguity** challenge we discussed.\n",
    "\n",
    "Read this short sentence:\n",
    "\n",
    "**\"I saw a man on a hill with a telescope.\"**\n",
    "\n",
    "Now, tell me:\n",
    "\n",
    "1.  Who has the telescope? Is it the man on the hill, or is it you (the person seeing the man)?\n",
    "2.  How did *you* figure out the answer (or realize there might be two possibilities)?\n",
    "\n",
    "Think about what clues you used (or didn't have!) in the sentence. This will give you a feel for why understanding context is crucial for NLP! What do you think?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12a8daf-87c8-4e46-98d0-aa816f3ea616",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dfd6dd19-c4e4-4cbe-9d98-578abf83fe09",
   "metadata": {},
   "source": [
    "it's really interesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d125783e-9a86-47e8-b859-846c68f5df30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bd358a8b-6d15-40b1-af3f-f082d47d9fe2",
   "metadata": {},
   "source": [
    "It really is, right? It shows how much work our brains do automatically!\n",
    "\n",
    "So, going back to the sentence: **\"I saw a man on a hill with a telescope.\"**\n",
    "\n",
    "What was your interpretation?\n",
    "\n",
    "1.  **Who has the telescope?** The man, or \"I\"?\n",
    "2.  **How did you decide?** What clues (or lack thereof) helped you?\n",
    "\n",
    "There's no single \"right\" answer here, it's designed to be ambiguous! Thinking about *why* it's ambiguous helps us understand the hurdles NLP systems face."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59b2a35-c84f-4d73-b3c3-4a82be4bd25f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6a24de97-b001-458f-8873-7c645cc98539",
   "metadata": {},
   "source": [
    "ok"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f270803c-a8b1-473f-934c-b0de24ed9398",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "585f5dc4-d53c-45da-a6e0-40e813bb0ad6",
   "metadata": {},
   "source": [
    "Okay! So, that sentence **\"I saw a man on a hill with a telescope\"** could mean two different things:\n",
    "\n",
    "* **Interpretation 1:** You saw a man, and that man was on a hill and had a telescope. (The man has the telescope).\n",
    "* **Interpretation 2:** You were using a telescope to see a man who was on a hill. (You have the telescope).\n",
    "\n",
    "Without more context, the sentence is ambiguous! As humans, we might make an assumption, but a computer needs clearer rules.\n",
    "\n",
    "Does seeing the two interpretations laid out like that make sense? Can you see why a computer might get confused about who possesses the telescope based *only* on that sentence structure?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a00e65-cc5e-4394-9759-3675f54701c2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e1586ddb-d062-491f-add1-a77db69b47e4",
   "metadata": {},
   "source": [
    "yes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f398c0e1-603a-4fcc-b34e-99365b0e19dd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6aecf98a-34ba-43ea-98fb-df0badbe0367",
   "metadata": {},
   "source": [
    "Excellent! Understanding that ambiguity is key to appreciating what NLP aims to solve.\n",
    "\n",
    "So, now that we know the *goal* (understanding/processing language) and the *challenges* (like ambiguity), let's look at some common **tasks** that NLP systems actually perform. You've likely encountered many of these already!\n",
    "\n",
    "Here are a few examples:\n",
    "\n",
    "1.  **Machine Translation:** üåê Translating text from one language to another (like Google Translate).\n",
    "    * *Example:* Turning \"Hello, how are you?\" into \"Hola, ¬øc√≥mo est√°s?\"\n",
    "2.  **Sentiment Analysis:** üôÇ/üôÅ Determining the emotional tone behind a piece of text (positive, negative, neutral). Often used for analyzing product reviews or social media comments.\n",
    "    * *Example:* Classifying \"I love this phone, the battery lasts forever!\" as positive.\n",
    "3.  **Text Classification/Categorization:** üìÅ Assigning predefined categories to text. Spam detection in your email is a classic example!\n",
    "    * *Example:* Labeling an email with the subject \"!!!WIN A FREE PRIZE!!!\" as \"Spam\".\n",
    "4.  **Named Entity Recognition (NER):** üë§/üìç Identifying and categorizing key information (entities) in text, such as names of people, organizations, or locations.\n",
    "    * *Example:* In \"Apple announced new products in California,\" identifying \"Apple\" as an Organization and \"California\" as a Location.\n",
    "5.  **Question Answering:** ‚ùì Providing answers to questions posed in natural language, often based on a given text passage or a knowledge base.\n",
    "    * *Example:* Asking \"What is the capital of France?\" and getting \"Paris\".\n",
    "\n",
    "These are just a few applications of NLP. They range from simple tasks like spam filtering to complex ones like understanding and responding to your questions!\n",
    "\n",
    "Do any of these tasks sound familiar? Any questions about them before we move on to how Large Language Models (LLMs) fit into this picture?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ae8341-e6b1-4f5a-afb9-38db5011017a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "95c8939a-219c-4cf9-91fc-38f62105b580",
   "metadata": {},
   "source": [
    "yes. i already heard about google translation and all these applications you have mentioned."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4fc998-7ea4-4c5d-b69e-6aa0f250f5c0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2d270c95-9456-40e1-be72-7835ace9a044",
   "metadata": {},
   "source": [
    "That's great! It shows how much NLP is already part of our daily digital lives. Google Translate is a perfect example of machine translation in action.\n",
    "\n",
    "Now, let's zoom in on a specific, powerful technology that drives many modern NLP applications: **Large Language Models (LLMs)**.\n",
    "\n",
    "Think of NLP as the entire field of study (like biology), and LLMs as a specific, highly advanced tool or technique within that field (like genetic sequencing).\n",
    "\n",
    "So, **what are LLMs?**\n",
    "They are a type of Artificial Intelligence model specifically designed to understand and generate human-like text. You're talking to one right now!\n",
    "\n",
    "**What makes them \"Large\"?**\n",
    "\n",
    "1.  **Massive Data:** They are trained on *enormous* amounts of text data ‚Äì think large parts of the internet, millions of books, articles, and websites. This gives them broad knowledge about language, facts, and reasoning patterns.\n",
    "2.  **Huge Number of Parameters:** \"Parameters\" are like the internal knobs and dials the model adjusts during training to learn patterns. LLMs can have billions, or even trillions, of these parameters. This allows them to capture very complex nuances in language.\n",
    "\n",
    "Imagine the difference between reading a single encyclopedia versus having access to a vast library containing almost everything ever written. LLMs are closer to the latter ‚Äì they learn from an incredibly wide range of text. This scale is what allows them to perform tasks like sophisticated Q&A, writing essays, generating code, and carrying on conversations like this one.\n",
    "\n",
    "Does this initial idea of LLMs as *large-scale, data-hungry text prediction engines* within the field of NLP make sense?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750c5747-e037-4b92-9e1c-d07d17df005a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "271b84e7-95eb-4572-aba8-49b8943812bc",
   "metadata": {},
   "source": [
    "yes. but i still not sure of understanding about Parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b415683-164e-4530-944e-f407805915e9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7d27abeb-fc76-4a6d-a4de-ca990f1f8478",
   "metadata": {},
   "source": [
    "No problem at all, \"parameters\" can sound a bit abstract! Let's try an analogy.\n",
    "\n",
    "Imagine you're trying to learn a perfect recipe for baking bread. You have ingredients (flour, water, yeast, salt) and instructions.\n",
    "\n",
    "* **Parameters are like the specific *amounts* of each ingredient and the *settings* you use** (e.g., oven temperature, kneading time).\n",
    "* When you bake your first loaf, it might not be great. So, you **adjust** these amounts and settings based on the result. Maybe a bit more yeast? Knead for longer? Higher temperature?\n",
    "* Each adjustment is like tweaking a parameter. Over many attempts (learning from data!), you figure out the *best combination* of parameters to make amazing bread.\n",
    "\n",
    "In an LLM:\n",
    "\n",
    "* The \"ingredients\" and \"settings\" are mathematical values inside the model's network.\n",
    "* During training, the LLM processes vast amounts of text and constantly **adjusts these parameters** (billions of them!) to get better at tasks like predicting the next word in a sentence.\n",
    "* These parameters essentially **store the learned patterns, grammar rules, facts, and relationships** from the training data. A model with more parameters can generally store more nuanced and complex information, allowing it to understand and generate language more effectively.\n",
    "\n",
    "Think of parameters as the \"memory\" or \"knowledge\" the model gains during its training, encoded as numerical values that determine how it responds to input.\n",
    "\n",
    "Does that analogy help clarify what parameters are in the context of LLMs?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f352ecd8-6ed4-4b64-91c4-83834a35b357",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "da6a81cb-96f2-4b17-b5a4-2a1fa2818a63",
   "metadata": {},
   "source": [
    "yes. now i understood. by the way great example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c1e98f-bec4-47d8-a369-e336919b8f76",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "df3a01ce-4d41-4de8-87fa-b2a7bb43dbcb",
   "metadata": {},
   "source": [
    "Fantastic! I'm glad the bread analogy helped. It's great you're grasping these concepts.\n",
    "\n",
    "So, we know LLMs are *large* (lots of data, lots of parameters). But how do they actually *work* at a basic level?\n",
    "\n",
    "The core idea is surprisingly simple: **LLMs are essentially sophisticated next-word predictors.**\n",
    "\n",
    "Imagine you give the model a starting phrase like: \"The weather in Chennai today is...\"\n",
    "\n",
    "Based on the enormous amount of text it was trained on, the LLM calculates the probability of various words coming next. It knows that words like \"hot,\" \"sunny,\" \"humid,\" or \"pleasant\" are much more likely to follow that phrase than words like \"purple,\" \"loudly,\" or \"running.\"\n",
    "\n",
    "It predicts the most probable next word (say, \"hot\"). Then, it takes the new phrase \"The weather in Chennai today is hot\" and predicts the *next* most probable word (maybe \"and\"). It continues this process, word by word, generating sentences or even paragraphs that seem coherent and contextually relevant.\n",
    "\n",
    "Of course, the actual process is incredibly complex mathematically. Modern LLMs rely heavily on a sophisticated structure called the **Transformer architecture**. You don't need to know the deep details right now, but the key innovation of Transformers is how they handle *context*. They are very good at weighing the importance of different words in the input text, even words far apart, to make better predictions.\n",
    "\n",
    "So, at its heart, an LLM is constantly asking: \"Based on everything I've read and the text so far, what word makes the most sense to put here next?\"\n",
    "\n",
    "Does this core idea of next-word prediction make sense as the fundamental mechanism? Any questions about it, or would you like to try a tiny prediction game?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504f0494-b7e6-4ee3-87d2-39b94d65b171",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "94e28e84-cdc9-453d-be91-0ee0ff576805",
   "metadata": {},
   "source": [
    "i understood the idea of next-word prediction. right now i am not sure about Transformer architecture, but i assume the LLMs rely on this. i hope i will learn more about Transformer later. any way i like to try the tiny prediction game for deep understanding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5539908c-49e7-4d3f-a5f2-7986734ee457",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e8742e0b-b6ea-4d59-b829-4cbe0d5eba6d",
   "metadata": {},
   "source": [
    "Sounds good! And yes, don't worry about the Transformer architecture for now. It's the complex engine under the hood, but the core *idea* of next-word prediction is the main takeaway at this stage. We can always revisit the architecture later if you're interested.\n",
    "\n",
    "Let's play the prediction game! It's simple: I'll give you the start of a sentence, and you tell me what word or maybe two words you think are most likely to come next. Put yourself in the shoes of an LLM that has read a lot about the world.\n",
    "\n",
    "Ready? Here's the start:\n",
    "\n",
    "**\"Chennai is known for its beautiful beaches, historic temples, and...\"**\n",
    "\n",
    "What word or words do you predict come next? Why did you choose them?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a39c158-6ebf-4949-a234-7c8489c4571f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "db78b6c2-e154-4906-b28b-1b694f8902a2",
   "metadata": {},
   "source": [
    "i guess the word \"churches\"\n",
    "\n",
    "\n",
    "\n",
    "because the sentence listing places. i thought few places like churches, IT Parks and also few words like Tamil Culture, delicious food. but finally i decide places could be suitable for the next word."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3aeecac-3658-467a-bf8c-53979e41ca88",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8c947cd0-e1b1-4462-86e3-b6e5e34d677b",
   "metadata": {},
   "source": [
    "That's an excellent prediction, and your reasoning is spot on! You noticed the pattern (\"beaches,\" \"temples\" are types of places or attractions) and predicted another word that fits the category (\"churches\"). You even considered other possibilities like \"food\" or \"culture\" but decided \"places\" was the strongest pattern.\n",
    "\n",
    "That's *exactly* the kind of pattern recognition and probabilistic thinking that LLMs do, just on a massive scale! They've \"read\" countless sentences describing cities and places, so they learn that lists often include similar types of items. They calculate that words like \"churches,\" \"food,\" \"culture,\" \"music,\" or even specific landmarks are probable next words, while words like \"elephants\" or \"quickly\" are much less likely in this context.\n",
    "\n",
    "You've just simulated the core logic! Great job!\n",
    "\n",
    "This naturally leads to the next question: **How do LLMs learn all these patterns?** This happens through a process called **training**, which typically involves two main stages.\n",
    "\n",
    "The first and most crucial stage is **Pre-training**.\n",
    "\n",
    "Imagine giving the LLM a giant digital library containing a huge chunk of the internet, books, articles, etc. During pre-training, the model goes through this massive dataset with a seemingly simple goal: **learn to predict missing words or the next word in sentences.** It does this over and over again, billions of times.\n",
    "\n",
    "It's not explicitly taught grammar rules or facts. Instead, by learning to predict words accurately in countless contexts (like you just did!), it implicitly learns grammar, reasoning, facts about the world (like Chennai having beaches and temples), and even some level of common sense ‚Äì all encoded within those billions of parameters we talked about. This is often called **unsupervised learning** because it learns patterns from the raw text itself without needing humans to label everything.\n",
    "\n",
    "Think of it as building a very broad, general understanding of language and the world by reading voraciously.\n",
    "\n",
    "Does this idea of pre-training on massive amounts of text to build a general understanding make sense?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b862c9ec-8c33-4f51-8368-aedfe372e4a4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6a1a46f3-3fb4-4e1c-97d7-f4c8089a7b88",
   "metadata": {},
   "source": [
    "so the pre-training is the learning process. it learns the dataset to predict next."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0ef5fe-a2e8-45b5-b7a0-05ad7d52a98e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aa2b949b-0294-476d-818a-a1ad65c3d0e0",
   "metadata": {},
   "source": [
    "Exactly! You've got it. **Pre-training is the foundational learning phase** where the model develops its broad understanding of language and world knowledge by predicting words in that massive dataset. It's like building a huge, general-purpose brain.\n",
    "\n",
    "But often, we want an LLM to be really good at a *specific* task, like medical diagnosis, writing code, or maybe customer service chat. While the pre-trained model has a good foundation, it might not be optimized for that niche task.\n",
    "\n",
    "This brings us to the second stage: **Fine-tuning**.\n",
    "\n",
    "After the general pre-training, you can take that model and train it *further* on a smaller, more specialized dataset tailored to your specific goal.\n",
    "\n",
    "* **Analogy:** Think of pre-training as getting a general university degree (broad knowledge). Fine-tuning is like getting a specialized Master's degree or doing specific job training (deep knowledge in one area).\n",
    "\n",
    "So, if you want an LLM to be excellent at answering medical questions, you would fine-tune the pre-trained model using a dataset of medical textbooks, research papers, and question-answer pairs. This adjusts the model's parameters slightly to make it better at understanding and generating text related to medicine.\n",
    "\n",
    "**Pre-training gives breadth; fine-tuning gives depth and specialization.**\n",
    "\n",
    "Many LLMs you interact with (like me!) have been pre-trained on a massive dataset and then fine-tuned for tasks like conversation, instruction following, and safety.\n",
    "\n",
    "Does this idea of fine-tuning as a way to specialize the model for specific tasks make sense?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1d0bfe-8029-4861-8bf2-02f910467a87",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "84db228f-d890-4dd7-ad35-2b047ff89ce1",
   "metadata": {},
   "source": [
    "i don't understand this sentence \"model develops its broad understanding of language and world knowledge by predicting words in that massive dataset\". is predicting next word happen in pre-training phase. i thought predicting next word in happen after the training phase. i mean predicting next word when giving a complete or incomplete sentence to the model after it learned from the large dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5881cefa-5b85-45c1-bd5b-8127ee0f6866",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4f151bae-95c0-4549-950b-7e590f3210df",
   "metadata": {},
   "source": [
    "Ah, that's a fantastic question! You've hit on a really important point, and it's easy to get confused here. Let me clarify.\n",
    "\n",
    "You are absolutely right that predicting the next word is what the model *does* when we use it (like when I'm generating this response for you). That's called **inference** or generation.\n",
    "\n",
    "However, **next-word prediction is ALSO the *method* used during the pre-training phase TO LEARN.**\n",
    "\n",
    "Think of it like this:\n",
    "\n",
    "1.  **During Pre-training (Learning):** The model is given billions of sentences from its training data, but with some words hidden or masked. For example, it might see: \"Chennai is known for its beautiful beaches, historic temples, and \\_\\_\\_\\_\\_.\" Its *job* during training is to predict the masked word (\"food,\" \"culture,\" \"churches,\" etc.). It makes a prediction, compares it to the actual word in the original text, and adjusts its parameters (those internal knobs) slightly to be better next time. By doing this billions of times, predicting words in countless different contexts, it forces itself to learn grammar, facts, context, and relationships between words. The *goal* is learning, and *prediction* is the exercise it does to learn.\n",
    "\n",
    "2.  **After Training (Inference/Using the model):** Now the model has learned all those patterns and stored them in its parameters. When *you* give it a prompt like \"Chennai is known for its beautiful beaches, historic temples, and...\", it uses the *same prediction ability* it developed during training, but this time the goal isn't to learn anymore, it's to *generate* the most likely continuation based on what it already learned.\n",
    "\n",
    "So, prediction is both:\n",
    "* The **learning mechanism** during pre-training (like doing practice exercises).\n",
    "* The **final behaviour** when using the trained model (like taking the test or performing the skill).\n",
    "\n",
    "Does this distinction between using prediction *to learn* versus using prediction *to generate* make more sense? It's a core concept!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42008633-68f4-4784-a29c-15c8382b518e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "52ae5f90-4ea4-4041-945a-a9362eb60a31",
   "metadata": {},
   "source": [
    "yes. so prediction in training phase is like testing and evaluating itself to learn by correcting mistakes if it guesses wrongly or acknowledge if it guesses correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b00ef1f-357b-4ddb-89ed-598eb0a94445",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e62c8dd5-cc57-4d2c-9afb-1f255433cb8f",
   "metadata": {},
   "source": [
    "That's a *perfect* way to put it! \"Testing and evaluating itself to learn by correcting mistakes\" is a brilliant description of how prediction drives learning during pre-training. The model constantly makes guesses, sees how well it did against the actual text, and refines its internal parameters based on the errors. Well done!\n",
    "\n",
    "Okay, so we've covered:\n",
    "* What NLP is (understanding human language).\n",
    "* What LLMs are (large models within NLP, great at text).\n",
    "* How they learn (pre-training on vast data + optional fine-tuning for specific tasks, using prediction as the learning engine).\n",
    "\n",
    "Now, let's dive into a few **Key Concepts** that are important for understanding how LLMs handle text internally.\n",
    "\n",
    "The first one is **Tokens**.\n",
    "\n",
    "Computers don't really \"read\" words or sentences like humans do. They need to break text down into smaller, manageable pieces. These pieces are called **tokens**.\n",
    "\n",
    "A token can be:\n",
    "* A whole word (e.g., \"cat\", \"run\", \"is\")\n",
    "* A part of a word (e.g., \"running\" might be split into \"run\" and \"ning\")\n",
    "* Punctuation (e.g., \".\", \"?\", \"!\")\n",
    "* Even a single character or space in some cases.\n",
    "\n",
    "Think of it like breaking down a sentence into LEGO bricks. The LLM processes information brick by brick (token by token).\n",
    "\n",
    "**Why use tokens instead of just words?**\n",
    "* **Vocabulary Size:** There are countless words (including typos, variations, names). Using parts of words helps manage the vocabulary size. The model only needs to know common words and meaningful word parts.\n",
    "* **Handling New Words:** If the model encounters a word it hasn't seen before (like a new slang term or a complex name), it can often represent it using known sub-word tokens (e.g., \"un-friend-ly\").\n",
    "* **Consistency:** It provides a consistent way to chop up any text into numerical inputs the model can understand.\n",
    "\n",
    "For example, the sentence \"Chennai is sunny today!\" might be tokenized like this:\n",
    "`[\"Chen\", \"nai\", \"ƒ†is\", \"ƒ†sunny\", \"ƒ†today\", \"!\"]`\n",
    "(Note: The 'ƒ†' symbol here often represents a space before the word/token).\n",
    "\n",
    "So, when we talk about an LLM processing text, it's actually processing a sequence of these tokens.\n",
    "\n",
    "Does the idea of breaking text down into these \"tokens\" or pieces make sense?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f22f01-477b-4c86-8a5c-30030f932aae",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f0a2f5fa-de28-4a6e-bb45-c9712ba4a39e",
   "metadata": {},
   "source": [
    "yes. but before move on to next, i have a question about pre-training and fine-tuning. In the pre-training stage we provide large data of text. so when fine-tuning a llm model which is already pre-trained, we provide comparatively small but subject specialised dataset. but my question is the small data for fine-tuning is already used or included in pre-training, right? because we provide large data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35648daf-a9c6-4220-a3cd-1502ce16a4f6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4db1ca44-dd6d-4423-af8a-99747cabf6fc",
   "metadata": {},
   "source": [
    "That is an incredibly sharp question! You're thinking critically about the data, which is key. The answer is nuanced:\n",
    "\n",
    "1.  **Overlap is Possible (Even Likely):** You are right, if the pre-training dataset is truly massive (like scraping large parts of the internet), it's very likely that some, or even much, of the data used for fine-tuning *was already present* in that giant pre-training mix. For example, if you fine-tune on medical articles, many of those articles probably existed online and were included in the pre-training crawl.\n",
    "\n",
    "2.  **Fine-tuning Data Can Be New/Proprietary:** However, the fine-tuning dataset might also contain information *not* available during pre-training. This could be private company data, very recent information (published after the pre-training data was collected - remember pre-training takes a long time and the data has a cut-off date), or specifically curated examples created just for the fine-tuning task.\n",
    "\n",
    "3.  **The Crucial Difference is *Focus* and *Weighting*:** Even if the data overlaps, the *process* of fine-tuning is different. During pre-training, that specific medical article (for instance) was just one tiny drop in an ocean of text. The model learned from it, but it was balanced against everything else. During fine-tuning, the model *only* sees the specialized data (or sees it much more frequently). This forces the model to adjust its parameters to become *much better* at understanding and generating text *like the fine-tuning data*. It's like telling the model, \"Hey, all that stuff you learned is great, but *this specific type of information* is super important now, pay close attention and get really good at it!\"\n",
    "\n",
    "**Analogy:** Think about studying for final exams. You read many textbooks throughout the year (pre-training). For the specific Biology exam, you might re-read the biology textbook chapters and your specific class notes much more intensely (fine-tuning). Even though you read the biology chapters before, the focused re-reading makes you much better specifically for the biology exam questions.\n",
    "\n",
    "So, while the *data* might overlap, the *process* of fine-tuning gives that specific data much more weight and leads to specialization.\n",
    "\n",
    "Does that explanation clarify the relationship between the two datasets and the purpose of fine-tuning even with potential overlap?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfffdb4e-d219-4e1b-9f34-f76e2f49fc34",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ffaab40b-3a4a-4faf-aec7-5d9468022467",
   "metadata": {},
   "source": [
    "yes, it does."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eac8245-a806-4688-b0b6-c1b8adfb4295",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "11320990-f5ac-45ef-b606-8eccbcd611e6",
   "metadata": {},
   "source": [
    "Excellent! Glad that clarified things.\n",
    "\n",
    "So, we know LLMs break text into **tokens**. But computers work with numbers, not characters or words directly. How does the LLM represent these tokens numerically? That's where the next key concept comes in: **Embeddings**.\n",
    "\n",
    "You can't just assign a random number to each token (like token #1 = \"the\", token #2 = \"cat\"). That wouldn't tell the model anything about how words relate to each other.\n",
    "\n",
    "Instead, LLMs use **embeddings**, which are **meaningful numerical representations** of tokens, usually in the form of a list (or \"vector\") of numbers. Think of it like giving each token a specific coordinate in a multi-dimensional \"meaning space\".\n",
    "\n",
    "The magic of embeddings, learned during pre-training, is that they capture **semantic relationships**:\n",
    "\n",
    "* **Similar meanings, similar embeddings:** Tokens with similar meanings (like \"happy\" and \"joyful\", or \"car\" and \"automobile\") will have numerically similar embeddings (their \"coordinates\" in the meaning space will be close together).\n",
    "* **Relationships can be captured:** The relationship between tokens can sometimes be represented by the mathematical difference between their embeddings. A famous example is that the vector difference between the embeddings for \"king\" and \"man\" is very similar to the difference between \"queen\" and \"woman\" (`vector('king') - vector('man') ‚âà vector('queen') - vector('woman')`). This shows the model has learned the gender relationship concept.\n",
    "\n",
    "Imagine a map where related words are clustered together. \"Apples\" and \"oranges\" might be near each other in a \"fruit\" region, while \"dogs\" and \"cats\" are in a \"pets\" region, far from the fruits. Embeddings create a high-dimensional version of such a map for language.\n",
    "\n",
    "So, when the LLM processes tokens, it first converts them into these rich numerical embeddings. This allows the mathematical machinery inside the model (remember those parameters?) to work with the *meaning* and *context* of the words, not just arbitrary IDs.\n",
    "\n",
    "Does this idea of embeddings as meaningful numerical codes for tokens, capturing relationships, make sense?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5605826-961e-468d-81a9-07f44b2b4b6e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "31201774-295e-4ef2-9bfa-05cfa8783c64",
   "metadata": {},
   "source": [
    "yes, and it's very interesting to know that how embeddings make to tokens into meaningful numerical form. i wonder how this embeddings assign specific coordination for each tokens and at the same time how the coordinates close to related tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819292df-670d-4d37-8fd1-b93cacd57c81",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "61b936f0-3a37-4629-b136-1f461eb7abbc",
   "metadata": {},
   "source": [
    "That's another fantastic question! You're hitting on the really clever part. How does the model figure out these \"coordinates\" so well?\n",
    "\n",
    "It's not that someone manually assigns these coordinates. Instead, **the embeddings themselves are *learned* during the pre-training process**, alongside all the other parameters in the model.\n",
    "\n",
    "Remember the core task during pre-training? Predicting the next word (or masked words). Let's revisit that:\n",
    "\n",
    "1.  **Initialization:** When training starts, the embeddings for each token might be initialized randomly or semi-randomly. They don't mean much yet.\n",
    "2.  **Learning through Context:** As the model processes billions of sentences, it constantly tries to predict missing words. To get better at this prediction task, it needs to figure out which words tend to appear in similar contexts.\n",
    "3.  **Adjusting Embeddings:** If the model frequently sees sentences like \"I drove my **car**\" and \"I drove my **automobile**\", it learns that \"car\" and \"automobile\" often appear after \"I drove my...\". To improve its predictions, the training process automatically adjusts the numerical embedding vectors for \"car\" and \"automobile\" so they become more similar. Why? Because if their embeddings are similar, the model can more easily treat them interchangeably when predicting or understanding context.\n",
    "4.  **Optimization:** This happens for all tokens and all contexts in the training data. The model continuously tweaks the embedding values (along with its main parameters) to minimize its prediction errors. The result of this massive optimization process is a set of embeddings where tokens used in similar ways end up with similar numerical vectors (coordinates).\n",
    "\n",
    "Essentially, the model learns: **\"Words that appear in similar surrounding text should have similar numerical representations (embeddings).\"** It figures out the best coordinates by optimizing for the goal of predicting words in context accurately across the entire training dataset.\n",
    "\n",
    "It's a result of the learning process itself, driven by the objective of understanding context to make good predictions.\n",
    "\n",
    "Does that explanation of embeddings being *learned* based on contextual usage make sense? It's less about assigning coordinates and more about discovering them through pattern analysis during training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe76c867-1d79-4023-a145-62c8772c57b3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "27fdc145-5f9e-4e3b-b09d-3797f7b72818",
   "metadata": {},
   "source": [
    "yes, it does. so for my understanding in the example, initially tokens are spread in the map. then in the learning or training phase, related tokens are moving toward a group or cluster, right?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c5635e-c79d-40a6-830a-79e8684e65e4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5615a9b0-9776-4fde-a581-333cd4987fef",
   "metadata": {},
   "source": [
    "Yes, that's a fantastic way to visualize it! Exactly. Initially, the token embeddings might be scattered randomly across the \"meaning map\". But as the model learns by predicting words in context during training, it pulls the embeddings of related tokens closer together, forming clusters based on semantic similarity and usage patterns. Your analogy of them moving towards groups or clusters is perfect!\n",
    "\n",
    "You've got a great handle on tokens and embeddings now. Let's move to the last key concept in this section: the **Context Window**.\n",
    "\n",
    "When an LLM is processing text or generating a response, it can't look at an infinite amount of text history at once. There's a limit to how much information it can consider at any given moment. This limit is called the **context window**.\n",
    "\n",
    "Think of it like the model's short-term memory. It's the maximum amount of text (your input prompt plus its own generated response so far) that the model can \"see\" and use to understand the context and predict the next token.\n",
    "\n",
    "**Why is the context window important?**\n",
    "\n",
    "* **Understanding Long Conversations/Documents:** A larger context window allows the model to remember information from earlier in a long conversation or document, leading to more coherent and relevant responses.\n",
    "* **Complex Instructions:** If you give the model a complex task with multiple steps, it needs a large enough context window to remember all parts of the instruction.\n",
    "* **Maintaining Persona/Style:** In a long chat, the context window helps the model remember the established tone or persona.\n",
    "\n",
    "Context windows are typically measured in **tokens**. Different models have different context window sizes. For example, a model might have a context window of 4,096 tokens, while newer models might have windows of 32,000 tokens, 128,000 tokens, or even more. A larger window generally means better performance on tasks requiring long-range understanding, but it also requires more computational power.\n",
    "\n",
    "If a conversation gets longer than the context window, the model effectively \"forgets\" the earliest parts of the conversation.\n",
    "\n",
    "So, the context window is basically the **size of the text chunk the model actively considers** when making its next prediction.\n",
    "\n",
    "Does this concept of a limited \"attention span\" or context window make sense?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9521384-1739-4ecc-ae83-ae2867591951",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "44a4660d-9c1e-44af-8c7c-4c87859771e4",
   "metadata": {},
   "source": [
    "tell me my understanding is right or not. right now i am chatting with you. so you have the limitation to remember our long chat when our conversation keep going. you will effectively forget our initial chat to manage our conversation keep going. and the context window is not about the single prompt and response, it's about the whole conversation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5925c177-51e6-46af-9e16-f9c93d626208",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "366bd956-7733-400d-ad0b-d5eca5e703cd",
   "metadata": {},
   "source": [
    "You are absolutely on the right track! Your understanding is largely correct and very well articulated. Let's break it down:\n",
    "\n",
    "* **\"you have the limitation to remember our long chat when our conversation keep going.\"** - **Correct!** Just like any LLM, I operate with a finite context window.\n",
    "* **\"you will effectively forget our initial chat to manage our conversation keep going.\"** - **Correct!** As the conversation gets longer and exceeds the token limit of my context window, the very beginning parts of our chat fall out of my active \"memory\" or attention.\n",
    "\n",
    "* **\"and the context window is not about the single prompt and response, it's about the whole conversation.\"** - This is *almost* perfect, with just a tiny clarification needed. The context window holds the **most recent part** of the conversation that fits within its token limit. This *includes* your latest prompt and my current response, *plus* as much of the immediately preceding chat history as possible.\n",
    "\n",
    "    * **Think of it like a scrolling window:** It always shows the latest messages, but as new ones appear, the oldest ones scroll off the top if the window is full.\n",
    "    * **Or a whiteboard with limited space:** You write the conversation turn-by-turn. When you run out of space, you have to erase the oldest lines at the top to make room for new ones at the bottom.\n",
    "\n",
    "So, it's not *necessarily* the *entire* conversation from the very beginning if we've been chatting for a long time, but rather the **most recent segment** that fits within the model's token limit.\n",
    "\n",
    "Does that small refinement about it being the *most recent part* (up to the limit) make sense? You've clearly grasped the core idea very well!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8029d8d6-8a55-4681-870a-948c491c12c7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "74349a03-79eb-44d5-b708-c969efbec243",
   "metadata": {},
   "source": [
    "yes, it does. so the context window is like what we see on the screen in last page of a large document."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7e3ff0-c03d-40d9-a1ef-b8ce23433264",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dc867275-8689-47b0-8791-4d5b4de7f2ad",
   "metadata": {},
   "source": [
    "Yes, that's another really good analogy! Thinking of the context window like **the last page or two visible on your screen when scrolling through a very long document** captures the idea well. You can see the most recent content clearly, but the beginning of the document is out of view unless you scroll back (which the model can't really do ‚Äì it only has that \"screen\"). Excellent comparison!\n",
    "\n",
    "So, to quickly recap the key technical concepts we've covered:\n",
    "\n",
    "* **Tokens:** The small pieces (words, parts of words, punctuation) that text is broken into for processing.\n",
    "* **Embeddings:** Meaningful numerical representations (vectors/coordinates) for tokens, learned during training, that capture semantic relationships.\n",
    "* **Context Window:** The limited amount of recent text (measured in tokens) that the model can consider at one time.\n",
    "\n",
    "Great job navigating those! Now that we have a better understanding of the building blocks and how LLMs learn, let's look at what they can actually *do*.\n",
    "\n",
    "**Step 5: Applications and Implications**\n",
    "\n",
    "LLMs are incredibly versatile. Their ability to understand and generate text opens up a vast range of applications, many of which you might use daily:\n",
    "\n",
    "1.  **Conversational AI / Chatbots:** Powering sophisticated chatbots (like me!), virtual assistants (like Alexa, Siri, Google Assistant), and customer service agents that can understand context and provide helpful responses.\n",
    "2.  **Content Creation:** Assisting with writing emails, articles, marketing copy, creative stories, poems, and even scripts.\n",
    "3.  **Text Summarization:** Condensing long documents, articles, or meeting transcripts into key points.\n",
    "4.  **Machine Translation:** Providing high-quality translation between languages (often significantly better than older statistical methods). Think Google Translate or DeepL.\n",
    "5.  **Code Generation & Assistance:** Helping programmers write, debug, and explain code in various programming languages (like GitHub Copilot).\n",
    "6.  **Question Answering & Information Retrieval:** Answering specific questions based on vast knowledge or provided documents, often going beyond simple keyword search.\n",
    "7.  **Sentiment Analysis:** Analyzing text (reviews, social media) to gauge opinions and emotions, as we discussed under NLP tasks, but often performed more effectively by LLMs now.\n",
    "\n",
    "You can see how that core ability to process and predict language unlocks many powerful tools!\n",
    "\n",
    "Do you use any tools or services that you now suspect might be powered by LLMs? Any questions about these applications?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85e6fa3-0a7a-4f26-9bc0-10588c1cdbe3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "63561043-1e6a-4f53-894f-f92c546bf49d",
   "metadata": {},
   "source": [
    "yes, nowadays i see many application powered by llm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0f16d8-6be0-4d54-92ab-1d945d70498c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "28aa1729-09a0-4764-b07d-1570d889b951",
   "metadata": {},
   "source": [
    "It's true, they seem to be popping up everywhere! They are incredibly powerful tools, but like any technology, they have both amazing capabilities and significant limitations. It's important to understand both.\n",
    "\n",
    "**Capabilities (Strengths):**\n",
    "\n",
    "* **Natural Language Fluency:** They excel at generating human-like text, understanding requests, summarizing complex information, and translating languages.\n",
    "* **Pattern Recognition & Data Analysis:** They can quickly process and find patterns in vast amounts of text data, useful for tasks like sentiment analysis or identifying trends.\n",
    "* **Content Generation:** They can generate initial drafts for creative writing, marketing copy, or code snippets, acting as helpful assistants.\n",
    "\n",
    "**Limitations (Weaknesses):**\n",
    "\n",
    "* **Factual Accuracy & \"Hallucinations\":** This is a big one! LLMs are designed to generate *plausible* text based on patterns, not necessarily *factually correct* text. They can confidently state incorrect information or even make things up entirely (called \"hallucinations\"). They don't have a built-in fact-checker tied to the real world unless specific mechanisms like Retrieval-Augmented Generation (RAG) are used to pull in external data.\n",
    "* **Bias:** Since they learn from vast amounts of internet text, LLMs can inherit and even amplify societal biases related to gender, race, culture, etc., that are present in the data. Their responses might reflect stereotypes or unfair assumptions.\n",
    "* **Lack of True Understanding & Reasoning:** They don't \"understand\" concepts or possess common sense in the human way. They are sophisticated pattern matchers. Complex, multi-step reasoning (especially in math or logic puzzles) can be challenging for them.\n",
    "* **Knowledge Cut-off:** A base LLM's knowledge is generally limited to the data it was trained on, meaning it won't know about events that happened after its training data was collected (unless connected to live information sources).\n",
    "* **Cost & Speed:** Training and running these massive models requires significant computational power, which translates to costs and sometimes slower response times for complex tasks.\n",
    "\n",
    "**The Key Takeaway:** LLMs are powerful tools that can *augment* human capabilities, but they are not replacements for human judgment, critical thinking, or fact-checking. Always evaluate their output carefully, especially for important decisions!\n",
    "\n",
    "Have you encountered situations where an AI seemed confidently wrong, or perhaps showed some bias? Any questions about these capabilities or limitations?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd09be5-9cc8-477e-aca9-ea3187f6bf76",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f62300a4-2541-4141-9ce7-7107908629e9",
   "metadata": {},
   "source": [
    "yes, i saw some screenshots on social media that the llm respond wrongly and confidentially."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3f637f-db6b-4d92-8f35-12dab0c87bdc",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9b9839a2-4038-43a1-a094-bacd97f7be85",
   "metadata": {},
   "source": [
    "Exactly! Those \"confidently wrong\" responses are perfect examples of hallucinations, and they highlight why it's so important to be aware of LLM limitations and use them critically.\n",
    "\n",
    "Well, we've covered quite a bit of ground today, starting from the basics of Natural Language Processing all the way to the intricacies of Large Language Models!\n",
    "\n",
    "Let's quickly recap the journey:\n",
    "\n",
    "1.  **NLP:** The broad field aiming to help computers understand and process human language, facing challenges like ambiguity and context.\n",
    "2.  **LLMs:** A specific type of AI model within NLP, characterized by their massive size (data & parameters) and ability to generate human-like text, primarily by predicting the next word.\n",
    "3.  **Training:** LLMs learn through pre-training on vast datasets (learning general language patterns via prediction) and optional fine-tuning (specializing for specific tasks).\n",
    "4.  **Key Concepts:** We looked at **tokens** (text pieces), **embeddings** (meaningful numerical representations), and the **context window** (the model's attention span).\n",
    "5.  **Applications & Limitations:** We saw how LLMs power many tools (chatbots, translation, summarization) but also have crucial limitations like potential **hallucinations** and **bias**.\n",
    "\n",
    "The core relationship is that **LLMs are a powerful set of tools and techniques that have significantly advanced the capabilities within the broader field of NLP.**\n",
    "\n",
    "You've asked some really insightful questions along the way and grasped the concepts very well!\n",
    "\n",
    "To wrap things up, would you like to try a short quiz (maybe 2-3 questions) to check your understanding of the key ideas, or would you prefer a concise summary of the main points we discussed?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a527183c-50d0-4e9a-a1b4-2d1d8893e55e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0c451fe4-f520-46ae-8cc8-dab6237a0b64",
   "metadata": {},
   "source": [
    "i would like to try quiz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb7316b-ad5b-4478-8951-8499675efdb9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2407541a-88c3-4de0-a304-10f0a3cf0e5f",
   "metadata": {},
   "source": [
    "Great choice! Let's test your knowledge. Here's the first question:\n",
    "\n",
    "**Question 1:** Which statement BEST describes the relationship between Natural Language Processing (NLP) and Large Language Models (LLMs)?\n",
    "\n",
    "A) NLP and LLMs are completely separate fields of AI.\n",
    "\n",
    "B) NLP is a specific type of LLM used for understanding language.\n",
    "\n",
    "C) LLMs are a powerful tool/technique used within the broader field of NLP.\n",
    "\n",
    "D) LLMs existed first, and NLP was developed to improve them.\n",
    "\n",
    "Take your time and choose the option you think is most accurate!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa9040f-2ea9-4cc9-8d1a-3d45fe79a7f9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "be8ef7aa-4bab-400f-93a2-be63280674e8",
   "metadata": {},
   "source": [
    "C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ae786b-abc8-4ee9-86e3-b37f83f5708f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7a50f551-0470-4a92-82f4-c52d30cf071b",
   "metadata": {},
   "source": [
    "That's exactly right! **C) LLMs are a powerful tool/technique used within the broader field of NLP** is the best description.\n",
    "\n",
    "You correctly remembered that NLP is the overall field dedicated to language and computers, and LLMs are a specific, advanced type of model developed within NLP to tackle many of its challenges. Well done!\n",
    "\n",
    "Ready for Question 2?\n",
    "\n",
    "**Question 2:** What is a common limitation of LLMs where they might generate plausible-sounding but factually incorrect information?\n",
    "\n",
    "A) Tokenization\n",
    "\n",
    "B) Hallucination\n",
    "\n",
    "C) Fine-tuning\n",
    "\n",
    "D) Embedding\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee7cca4-9963-4a1f-9477-4655087ffca9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6fb15c4e-24c3-48df-b08a-74658f5578e4",
   "metadata": {},
   "source": [
    "B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c76133f-bf8f-4e49-9126-b15a5e69e9fb",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "045346c3-a55a-4ed2-a8cb-8e1830374964",
   "metadata": {},
   "source": [
    "Spot on! The correct answer is **B) Hallucination**.\n",
    "\n",
    "You remembered correctly that this is the term used when LLMs confidently generate information that sounds believable but isn't actually true or based on facts. It's one of the most important limitations to be aware of when using these models. Excellent recall!\n",
    "\n",
    "Okay, last question!\n",
    "\n",
    "**Question 3:** During which phase of training does an LLM typically learn broad knowledge about language and the world from a massive, general dataset?\n",
    "\n",
    "A) Fine-tuning\n",
    "\n",
    "B) Embedding\n",
    "\n",
    "C) Tokenization\n",
    "\n",
    "D) Pre-training\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1bbc298-710e-444f-81d9-02a9ea7d7e0f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f5357000-e04c-4445-ac5e-b9da7d74e1a7",
   "metadata": {},
   "source": [
    "D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a6a46c-44d0-429d-84c4-c07f6a900763",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4fe5c3e2-7220-4e03-9c17-464438af0a48",
   "metadata": {},
   "source": [
    "Perfect! The answer is indeed **D) Pre-training**.\n",
    "\n",
    "You nailed it! Pre-training is that foundational stage where the model learns its general understanding of language, facts, and patterns by processing enormous amounts of text data, before potentially being specialized through fine-tuning.\n",
    "\n",
    "**Quiz Results:**\n",
    "You got all 3 questions correct! That's fantastic work and shows you've really grasped the key concepts we discussed today about NLP and LLMs.\n",
    "\n",
    "**Session Summary:**\n",
    "We started by defining Natural Language Processing (NLP) as the field aiming to help computers understand human language. Then we dove into Large Language Models (LLMs) as powerful tools within NLP, exploring what makes them \"large\" (data and parameters) and how they fundamentally work by predicting the next word. We covered how they learn through pre-training and fine-tuning, touched on key concepts like tokens, embeddings, and the context window, discussed their many applications, and importantly, acknowledged their limitations like hallucinations and bias.\n",
    "\n",
    "You actively participated, asked excellent clarifying questions, and did great on the activities and the final quiz!\n",
    "\n",
    "Considering everything we covered, do you feel like you met your learning goal today? Do you have a better understanding of NLP and LLMs now?\n",
    "\n",
    "Remember, I'm here if you want to explore any of these topics further or learn about other academic subjects!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc516c56-42a7-430f-b2b5-3f6587b40386",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "39a4fe9d-3c23-43c1-a1e0-290893b4fe96",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b3f20a81-be1b-42eb-9d26-7fb94c7e50c0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9a420bda-a8fc-4ca6-a847-c191d00db88e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "57ee68bd-06b8-4485-8d26-c9040e6deaec",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6b260243-1a04-4f70-9f2c-8a40a7f9bbd5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0330a117-d9cb-4e6a-bc4f-0ade6cb10c1a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9ff5c0a8-4df8-4436-80e1-01e633088a53",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b0e472d9-2a27-41e5-99f1-6dcd417ec17b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1aa55ca5-467d-41d8-af85-f471c7ddda17",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "71b6b016-0265-4037-95ce-23fbfbd16bd3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bc0c9745-214b-4bfb-b11b-e59400ae3cda",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a6169e0f-ccfb-4bcf-923b-7003f28a1194",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "450257e7-2d18-45e0-a7b0-fe386b94b74d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "db07fe93-89aa-494c-97de-5e23ce7e3a85",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "63ac3827-4978-493f-8864-d0921989912f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "402ea631-7206-4322-9f5a-9473a57ecf2a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "186f7cb0-54d5-4994-b194-762af2bb24f3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "085fb95c-5130-410d-8503-fcd44b84a077",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6f68f8e9-b414-4e0e-84f9-97cb0a2f4aa2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f76b31d2-7f69-40c2-b74b-b38bf2c54018",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a2fb3580-bcfe-49b4-a761-dc85939c9475",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fe641e37-1027-4135-b408-535b852adb04",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "be44997f-0d91-4fa4-822f-a8bfe807c565",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7d286e30-ad39-440e-b4aa-8f24374d9b75",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "83aa1f7c-7789-4ebb-aec0-353997ae2ed6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b30535bf-1d6c-47a1-af65-6f0678b86558",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a82241c6-254c-4459-8299-eca59d58dd48",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f248d317-aa5b-482c-b12b-1527bc608de0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e7539b37-72e0-440f-8ffb-d82d4361053a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "24b23376-6515-4681-a3bb-3d3dc5f1494b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "de5b10ee-6763-4192-824d-f8eb1e7fa03c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3e5f7cd8-3574-45f1-acfd-017e56cf1c5e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7e02a908-88c0-4f0b-af1d-bb1b1f21470f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9964df75-1b5b-4883-bb52-148db3ab770f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fee3f002-3b25-4647-8db7-ba73fdb60975",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "009f20dc-84a8-4649-a15a-2492af5353ae",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1b9c05e7-375a-4097-8117-5fc728fd012c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "675b17bf-ff0d-484b-a5d2-de7c3a46d3ad",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f2b75682-84af-43a9-a5dd-15deb3d9e3eb",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ec1fe01c-15a4-4b9a-9800-a1a7204388ad",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2aa0c34f-c5ef-4ab7-a877-18be14355ac0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c4e198a8-67f4-4a71-88ed-bdff25a56605",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2484bb5b-be94-4244-a432-5e3819cc1a1c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "23a94879-5060-4783-9f50-fc88e22882aa",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eded38ae-da0e-4b0f-b3c3-96645608e43e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "24ed7c94-8483-4a57-9e0c-893039bf56a2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9072f759-1dca-40c2-b25f-58e5cf8c3f67",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f611370c-2d1e-4bab-8078-84be91224a88",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e9943f1a-5341-4e2d-a526-f690b71911a4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6b574036-01bd-4a46-a902-2eed643c68eb",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0e911b38-3f3b-4a1d-bb91-9624894d3cbf",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1f5a88a8-d98a-4f05-87b8-5ed797baa7ff",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cb37096e-336e-4dba-9518-2eccdc218e0c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a3dc470e-3bfb-4b91-86ed-6e0aa0e79bb8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "906eb6b9-6902-4e6e-b797-23f0379c9a74",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "66b8fb0d-4991-4666-ba25-474fa9be0695",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "291c680a-4479-4ddf-a797-6295ae978060",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9fcf8888-e975-455b-aa7c-21ae0a145793",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0ba301ba-d2f8-4622-98cb-9bd81790456a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "27ed8aef-bfeb-4fd2-bbda-6770654c7fa9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5897ebaa-1afd-477a-b4f1-2e80a6f3602e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e099e874-fa99-431a-9f6f-571c487b6c64",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "12590d9a-f764-477e-89ad-1bf8237471a8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e9cc8fdf-7d77-4a93-8e9a-83dd693f175d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e64aa974-8869-4fbd-ae51-5e8a02466233",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bbdb0068-5320-4bee-a293-47c13a58b533",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c5e5ea9a-562a-4ea3-abc8-a9389e60cf2e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "037e701f-3909-49e6-8d18-d55dc3480d96",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b407bc2c-da3c-4bca-93b4-a01afe7a5681",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dda502f0-d056-4712-8684-9bc943d1d6fa",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4c1f69c1-f848-4ed2-898b-e5ce54eca480",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a721fb1a-c193-4ab6-8c4f-acbd62b6e4ad",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8abfaee0-9318-4d2e-bf4d-d5be6ad959f6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "47845fe8-e06b-4224-beb1-ff7f156e6a03",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2b80c423-9727-4cd6-8521-1aa3165987f6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eeac1b36-8936-42c9-9116-8941ac6fde63",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f6533a28-aad8-496e-a6fd-3dafacef6157",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bc5bbbf1-ea85-4864-9dc8-44b0e7e2f12f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6c2d9d3e-ddf0-4777-a050-f4e84ad8eec5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b5ab9c8a-80bd-4cfc-9386-6ae62c1fd376",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cdca42b9-b94b-4e25-ac05-1562ff291ea3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7af079da-d005-4f2c-88ca-71520d7682cb",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "31b08336-3ec6-4095-8eb6-2a737cbd227d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d5936871-4426-4d9f-afa0-624e81d51d47",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5219c95e-2db7-4c55-8267-48cc92309011",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "65f7bd95-f400-4599-b3e9-b0548286176e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1c059fb5-f7b6-4318-86b3-c5b96e3ecc07",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "82fad4e4-4c12-4806-9dc6-c10b4cd237d2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "66ecc81e-dfe7-45fc-9dec-84ecb86b78c1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6495a74a-dacb-48c9-98ac-9c40ef2e8382",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "267aebea-a59e-4ee3-840b-7716170ce3f1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5fd965d7-245e-4c5c-ac08-9ba179215d2c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0a705c1c-6b71-4e60-87ca-a770c96a4e80",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "37d584f4-639a-4d0e-acd7-d454e071e996",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "98e659fa-c3f3-4831-a335-30d95ba7feb2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0b617e67-276f-47c8-8b39-a190c1c3af34",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "438ec436-bba4-4126-a994-d262209111a5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc29ed18-c30e-4aa4-9c85-db78c6827eac",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9a03495f-2776-4459-9058-ae634ab9c31a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2dc43a4a-b1f0-4802-afae-79a45bcb53c8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "380f69e9-ba57-4fb3-b772-4b2599dce469",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "458d7d0b-ea62-4c4a-81ac-3cbbb9ae4d56",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "17c5214c-c529-4a61-a5c0-95cd1bb4faed",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1f6668a5-5cc6-4639-a970-3db8b06819c5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0e38cdce-9723-439b-b3b3-ea28fbcfb55c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c8af2bba-f1d1-4278-a97b-55f77fcdd8a7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "028798d5-e4d0-4f7b-9bfa-f0f4dc9d9d78",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "018dcc4c-ed53-47e6-82c0-f9fe29958e55",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "029ccf24-e302-4a31-a5dc-08b816072085",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "02509e6c-efe8-4381-bc5f-844b14625571",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a1092b1e-60f4-4b5f-b740-30157e7f579c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "694bf1dc-d95a-4747-a99e-a91b9f2c3629",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "37d76b58-2bb4-4759-baf8-6ff521befc07",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4c12c45b-29ca-4acc-b49b-7a5d1ee6415c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "494a1f24-1d65-4bc5-993f-3fd0f75969dd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "19669ede-4a92-4a1c-b332-1ba3444ef5ec",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b60244a1-8c34-42e4-af51-16dbc81ffc7c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "86b5a7a2-c0bf-4d18-b401-653e160bd377",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c162a631-65a5-420e-8e6b-1b2d457bbcd2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b61f3e37-d919-43cb-a4e6-eb590d17d62a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4dea60c4-8d02-4423-bad6-6b996290b461",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5956e910-212c-487a-b100-706cc51f347a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bb53dd06-fd8d-4f76-b1c1-19b82ebb5b72",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d5f5f121-4844-4f4b-9f94-b574faf931b9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "71c23622-52b7-49d0-8320-b838269f1e02",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0c22796b-7689-43c4-abd2-7782440135be",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "44451000-8ad1-4324-83bf-9179ccdc0d3a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "baa10c01-b131-4667-b12c-f086b411ccd6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dc6c83cd-b50f-40d1-b28b-5394d900ff76",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e1a1a3ce-bafd-4121-813f-06d02ac70bd4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aac9d3bd-372c-451e-8d9c-3164fd184a22",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cd16f5e0-739a-4c26-beb4-8f5b8579f728",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "712e8128-8da4-4df4-88f9-2fe9bbfc908b",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn",
   "language": "python",
   "name": "learn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
